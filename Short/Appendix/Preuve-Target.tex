\section{Proof of Proposition~\ref{prop:target-undec}}
\label{app:target}

\propTargetUndecidable*

\begin{proof}
	We present a reduction from the halting problem for Minsky machines to \COVER for "signature BNRA".
	
	A Minsky Machine with two counters is a tuple $M= (\Loc, \Delta, \Cpt, \ell_0, \ell_f)$ where $\Loc$ is a finite set of locations, $\Cpt = \{\cpt_1, \cpt_2\}$ is a set of two counters, $\Delta \subseteq \Loc \times \set{\dec{\cpt},\inc{\cpt},\testz{\cpt} \mid \cpt \in \Cpt} \times \Loc$ is a finite set of transitions, $\ell_0 \in \Loc$ is an initial location and $\ell_f \in \Loc$ is a final location. A \emph{configuration} of a Minsky machine is a tuple $(\ell, v_1, v_2) \in \Loc \times \nats \times \nats$ where $v_1$ (resp. $v_2$) stands for the value of the counter $\cpt_1$ (resp. $\cpt_2$). 
	We write $(\ell, v_1, v_2) \stepMM{} (\ell', v'_1, v'_2)$ if there is $\delta \in \Delta$ such that:
	\begin{itemize}
		\item $\delta = (\ell, \inc{\cpt_i}, \ell')$ and $v'_i = v_i+1$, $v_{3-i} = v'_{3-i}$;
		\item $\delta = (\ell, \dec{\cpt_i}, \ell')$ and $v'_i = v_i-1$, $v_{3-i} = v'_{3-i}$;
		\item $\delta = (\ell, \testz{\cpt_i}, \ell')$ and $v'_i = v_i = 0$, $v_{3-i} = v'_{3-i}$.
	\end{itemize}
	%	We will note $\stepMM{}$ for $\bigcup_{\delta \in \Delta} \stepMM{\delta}$. 
	An execution of the machine is a sequence $(\ell_1, v_1^{(1)}, v_2^{(1)}) \stepMM{} (\ell_2, v_1^{(2)}, v_2^{(2)}) \stepMM{} \dots \stepMM{} (\ell_k, v_1^{(k)}, v_2^{(k)})$. 
	The halting problem asks whether $\ell_f$ is coverable. This problem is well-known to be undecidable \cite{minsky}.
	
	
	\begin{figure}
		% \centering
		% \begin{minipage}{.5\textwidth}
			\centering
			\resizebox{.99\linewidth}{!}{
			\input{Figures/target-init}
			}
			\caption{Partial depiction of the protocol built in Proposition~\ref{prop:target-undec}. Only one transition, which is $(\ell_0, \delta, \ell_1)$, is represented in the $\prot_{\mathsf{loc}}$ part above; similarly, only one increment and one decrement transitions are depicted in the $\prot_{\mathsf{count}}$ part below. The rebroadcast loops rebroadcast all transitions acting on $\cpt_2$ and all acknowledgements; the one on $(\cpt_1,0)$ also rebroadcasts all transitions with $\dec{\cpt_1}$ and with zero-tests, and the one on $(\cpt_1,1)$ rebroadcasts all transitions with $\inc{\cpt_1}$.}
			\label{fig:target-init}
		% \end{minipage}%
		% \begin{minipage}{.5\textwidth}
		% 	\centering
		% 	\input{Figures/cycle-knowledge}
		% 	\caption{Cycle of knowledge of 4 agents. Each box represents an agent along with its register values.}
		% 	\label{fig:target-cycle-knowledge}
		% \end{minipage}
	\end{figure}
	
	Fix a Minsky Machine $M= (\Loc, \Delta, \Cpt, \ell_0, \ell_f)$. We build a "signature protocol" $\prot$ with a state $q_f$ such that $(\prot, q_f)$ is a positive instance of \TARGET if and only if $\ell_f$ is coverable in $M$. 
	The protocol is represented in Figure~\ref{fig:target-init}. 
	As in Proposition~\ref{prop:reduction-LCS}, in an initial phase, each agent picks a predecessor by storing its identifier and only listens to this predecessor afterwards. We call \emph{cycle} a sequence of agents $a_1, a_2, \ldots, a_n = a_1$ where agent $a_i$ is the predecessor of $a_{i+1}$ for all $i <n$. 
	As all agents have to reach the end state, they must all pick a predecessor.
	As there are finitely many agents in a run, a cycle will necessarily be formed in any run satisfying the \TARGET requirement.
	
	The rest of the construction aims at faithfully simulating the machine in a cycle: Agents in $\prot_{\mathsf{loc}}$ sends a sequence of instructions and waits after each one for a confirmation that it was executed. Agents in $\prot_{\mathsf{count}}$ simulate counter values. The messages circulating in a cycle contain either a transition $\delta \in \Delta$ or an acknowledgment $\overline{\delta}$ with $\delta \in \Delta$. 
	An agent $a$ in $\prot_{\mathsf{count}}$ first picks a counter $\cpt_i$ it simulates, and goes to state $(\cpt_i,0)$. If $a$ is in ($\cpt_i,0)$ and receives $\delta$ corresponding to an increment of $\cpt_i$, it goes to $(\cpt_i,1)$ and broadcast an acknowledgment $\overline{\delta}$, and conversely for decrements. If $\delta$ is a zero-test $\testz{\cpt_i}$ and $a$ is on state $(\cpt_i,1)$ then it stops, making the whole cycle fail. Otherwise it broadcasts the acknowledgment $\overline{\delta}$. Other messages are rebroadcast as such. 

	An agent $a$ in $\prot_{\mathsf{loc}}$ starts in state $\mathsf{loc}(\ell_0)$. When in state $\mathsf{loc}(\ell)$, it picks and broadcasts a transition $\delta = (\ell, \anact, \ell') \in \Delta$, waits for the acknowledgment $\overline{\delta}$ and goes to $\mathsf{loc}(\ell')$. In the case where $\delta$ is a zero-test, we have $\overline{\delta} = \delta$: there is no need for a distinct acknowledgment because there is no action to perform (if the test fails then no message is transmitted). When in $\mathsf{loc}(\ell_f)$, $a$ broadcasts a special message $\mathsf{end}$ that propagates in the cycle and makes everyone go to $q_f$. When it receives itself the message $end$, it goes to $q_f$. 
	
	It is quite easy to see that, if $\ell_f$ can be covered in $M$, one can build a run of $\prot$ where all agents end in $q_f$. Let $N$ the highest counter value in the execution of $M$ covering $q_f$. The run of $\prot$ first puts all its agents in the same cycle; exactly one agent $a_\mathsf{lead}$ goes in $\prot_{\mathsf{loc}}$ and $2N$ agents go in $\prot_{\mathsf{count}}$; half of these simulate $\cpt_1$ and half $\cpt_2$, so that the largest counter value is never exceeded. It then suffices to faithfully simulate the execution of $M$: $a_\mathsf{lead}$ selects the corresponding sequence of transitions, their effect is always applied as we have enough agents simulating each counter. After each round the number of agents in state $(\cpt_i,1)$ is exactly the value of $\cpt_i$ at this point in the run of the machine, hence zero-tests never cause failure. In the end $a_\mathsf{lead}$ reaches $\mathsf{loc}(\ell_f)$ and broadcasts $\mathsf{end}$, allowing every agent in $\prot_{\mathsf{count}}$ to get to $q_f$.

	For the converse implication, suppose that we have a run $\run$ of $\prot$ where all agents end in $q_f$. As mentioned before, there must be a cycle of agents $a_1, \dots, a_n$ in this run. Observe that all agents alternate between broadcasts and receptions, so that to reach $q_f$ they must all have made the same number of broadcasts and receptions. This implies that no message was lost along the cycle.
	
	Note that there may be several agents in $\prot_{\mathsf{loc}}$ along the cycle; however, they must all broadcast exactly the same sequence of transitions, otherwise one of them would lack an acknowledgment and would not get to $q_f$. Let $a$ be the agent that first reaches $\mathsf{loc}(\ell_f)$ and $a'$ the first agent in $\prot_{\mathsf{loc}}$ after $a$ in the cycle; there are only agents in $\prot_{\mathsf{count}}$ between $a$ and $a'$ in the cycle, we call these agents \emph{intermediate agents}. The intermediate agents faithfully encode the two counters and all decrements and zero-tests pass, otherwise $a'$ would lack an acknowledgment. Therefore, the sequence of transitions of $a$ defines an execution of $M$ that covers $\ell_f$, which concludes the proof.  
\end{proof}